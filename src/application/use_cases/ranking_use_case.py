# src/application/use_cases/ranking_use_case.py

import asyncio
import json
import re
import pandas as pd
from datetime import datetime, timedelta

# Custom Module Imports
from application.agents.naver_review.naver_review_agent import NaverReviewAgent
from src.infrastructure.external_services.naver_search.naver_review_api import (
    get_naver_trend,
    search_naver_blog,
)
from src.application.core.graph import app_llm_graph
from src.infrastructure.llm_client import get_llm_client
from src.application.core.constants import NO_IMAGE_URL


class RankingUseCase:
    def __init__(self, naver_supervisor: NaverReviewAgent):
        self.naver_supervisor = naver_supervisor

    def _get_trend_score(self, keyword: str, days: int) -> float:
        if not keyword:
            return 0.0
        today = datetime.today()
        start_date = today - timedelta(days=days)
        trend_data = get_naver_trend(keyword, start_date, today)
        if not trend_data:
            return 0.0
        df = pd.DataFrame(trend_data)
        if "ratio" in df.columns and not df["ratio"].empty:
            return df["ratio"].mean()
        return 0.0

    async def _get_sentiment_score(
        self, keyword: str, num_reviews: int
    ) -> tuple[float, list]:
        if not keyword:
            return 50.0, []

        search_keyword = f"{keyword} í›„ê¸°"
        api_results = search_naver_blog(
            search_keyword, display=num_reviews + 5
        )  # Add buffer
        if not api_results:
            return 50.0, []

        candidate_blogs = []
        for item in api_results:
            if "blog.naver.com" in item["link"]:
                item["title"] = re.sub(r"<[^>]+>", "", item["title"]).strip()
                if item["title"] and item["link"]:
                    candidate_blogs.append(item)
            if len(candidate_blogs) >= num_reviews:
                break

        if not candidate_blogs:
            return 50.0, []

        total_strong_pos = 0
        total_strong_neg = 0
        total_sentiment_frequency = 0
        all_positive_judgments = []

        for blog_data in candidate_blogs:
            try:
                content, _ = await self.naver_supervisor._scrape_blog_content(
                    blog_data["link"]
                )
                if not content or "ì˜¤ë¥˜" in content or "ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤" in content:
                    continue

                max_content_length = 30000
                if len(content) > max_content_length:
                    content = content[:max_content_length]

                final_state = app_llm_graph.invoke(
                    {
                        "original_text": content,
                        "keyword": keyword,
                        "title": blog_data["title"],
                        "log_details": True,
                        "re_summarize_count": 0,
                        "is_relevant": False,
                    }
                )

                if not final_state or not final_state.get("is_relevant"):
                    continue

                judgments = final_state.get("final_judgments", [])
                if not judgments:
                    continue

                all_positive_judgments.extend(
                    [j for j in judgments if j["final_verdict"] == "ê¸ì •"]
                )
                pos_count = sum(
                    1 for res in judgments if res["final_verdict"] == "ê¸ì •"
                )
                neg_count = sum(
                    1 for res in judgments if res["final_verdict"] == "ë¶€ì •"
                )
                strong_pos_count = sum(
                    1
                    for res in judgments
                    if res["final_verdict"] == "ê¸ì •" and res["score"] >= 1.0
                )
                strong_neg_count = sum(
                    1
                    for res in judgments
                    if res["final_verdict"] == "ë¶€ì •" and res["score"] < -1.0
                )

                total_strong_pos += strong_pos_count
                total_strong_neg += strong_neg_count
                total_sentiment_frequency += pos_count + neg_count
            except Exception:
                continue

        if total_sentiment_frequency == 0:
            return 50.0, []

        sentiment_score = (
            total_strong_pos - total_strong_neg
        ) / total_sentiment_frequency * 50 + 50
        return sentiment_score, all_positive_judgments

    async def _summarize_trend_reasons(self, keyword: str) -> str:
        if not keyword:
            return "í‚¤ì›Œë“œê°€ ì—†ì–´ íŠ¸ë Œë“œ ë¶„ì„ ë¶ˆê°€"
        today = datetime.today()
        start_date = today - timedelta(days=90)
        trend_data = get_naver_trend(keyword, start_date, today)
        if not trend_data:
            return "íŠ¸ë Œë“œ ë°ì´í„° ì—†ìŒ"
        df = pd.DataFrame(trend_data)
        data_str = df.to_string()
        llm = get_llm_client(temperature=0.2)
        prompt = f"""
        ë‹¤ìŒì€ '{keyword}'ì— ëŒ€í•œ ìµœê·¼ 90ì¼ê°„ì˜ ë„¤ì´ë²„ ê²€ìƒ‰ëŸ‰ íŠ¸ë Œë“œ ë°ì´í„°ì…ë‹ˆë‹¤.
        
        [ë°ì´í„°]
        {data_str}

        [ìš”ì²­]
        1. ë°ì´í„°(ë‚ ì§œë³„ ê´€ì‹¬ë„ ë¹„ìœ¨)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ, ê²€ìƒ‰ëŸ‰ íŠ¸ë Œë“œì˜ í•µì‹¬ íŠ¹ì§•ì„ 1-2ì¤„ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”.
        2. ë§Œì•½ ì£¼ë§/í‰ì¼ ê°„ì˜ ëª…í™•í•œ ì°¨ì´ë‚˜ íŠ¹ì • ì‹œì ì˜ ê¸‰ë“± ê°™ì€ íŒ¨í„´ì´ ë³´ì¸ë‹¤ë©´, ë°©ë¬¸ ì‹œ ì°¸ê³ í•  ë§Œí•œ íŒì„ í•œ ë¬¸ì¥ ì¶”ê°€í•´ì£¼ì„¸ìš”.

        [ì¶œë ¥ ì˜ˆì‹œ 1 - ê¾¸ì¤€í•œ ê²½ìš°]
        "ìµœê·¼ í•œ ë‹¬ê°„ ê´€ì‹¬ë„ê°€ ê¾¸ì¤€íˆ ì¦ê°€í•˜ê³  ìˆì–´, í˜„ì¬ ê°€ì¥ ì£¼ëª©ë°›ëŠ” ì‹œê¸°ì…ë‹ˆë‹¤."
        
        [ì¶œë ¥ ì˜ˆì‹œ 2 - ì£¼ë§ í¸ì¤‘ì˜ ê²½ìš°]
        "ì£¼ë¡œ ì£¼ë§ì— ê´€ì‹¬ë„ê°€ ê¸‰ì¦í•˜ëŠ” ê²½í–¥ì„ ë³´ì…ë‹ˆë‹¤. ì—¬ìœ ë¡œìš´ ë°©ë¬¸ì„ ì›í•œë‹¤ë©´ í‰ì¼ ë°©ë¬¸ì„ ê³ ë ¤í•´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        """
        try:
            response = await llm.ainvoke(prompt)
            return response.content.strip()
        except Exception as e:
            return "íŠ¸ë Œë“œ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ"

    async def _summarize_sentiment_reasons(
        self, positive_judgments: list, keyword: str
    ) -> str:
        if not positive_judgments:
            return "ê¸ì • ë¦¬ë·°ê°€ ì—†ì–´ ë¶„ì„ ë¶ˆê°€"
        sentences = [j["sentence"] for j in positive_judgments]
        sentences_str = "\n- ".join(sentences[:20])
        llm = get_llm_client(temperature=0.2)
        prompt = f"""
        ë‹¤ìŒì€ '{keyword}'ì— ëŒ€í•œ ë¸”ë¡œê·¸ ë¦¬ë·°ì—ì„œ ì¶”ì¶œëœ ê¸ì •ì ì¸ ë¬¸ì¥ë“¤ì…ë‹ˆë‹¤.
        ì´ ë¬¸ì¥ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ, ì‚¬ìš©ìë“¤ì´ ì£¼ë¡œ ì–´ë–¤ ì ì„ ì¹­ì°¬í•˜ëŠ”ì§€ í•µì‹¬ì ì¸ ì´ìœ  1~2ê°€ì§€ë¥¼ ìš”ì•½í•´ì£¼ì„¸ìš”.

        [ê¸ì • ë¬¸ì¥ ëª©ë¡]
        - {sentences_str}

        [ì¶œë ¥ ê·œì¹™]
        - "ë„¤, ...í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤" ì™€ ê°™ì€ ì„œë¡ ì´ë‚˜ ë¶ˆí•„ìš”í•œ ì„¤ëª…ì€ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
        - ë¶„ì„ëœ í•µì‹¬ ì´ìœ ì— ëŒ€í•œ ìš”ì•½ ë‚´ìš©ë§Œ ë°”ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.

        [ì¢‹ì€ ì¶œë ¥ ì˜ˆì‹œ]
        'ê¹¨ë—í•œ ì‹œì„¤ê³¼ ë‹¤ì–‘í•œ ë¨¹ê±°ë¦¬ì— ëŒ€í•œ ì¹­ì°¬ì´ ë§ìŠµë‹ˆë‹¤.'
        'ì‹¤ê° ë‚˜ê³  ì¸ìƒì ì¸ ë¯¸ë””ì–´ ì•„íŠ¸ì™€, ì‚¬ì§„ ì°ê¸° ì¢‹ê²Œ ì•„ë¦„ë‹µê²Œ ê¾¸ë©°ì§„ ê³µê°„ì— ëŒ€í•œ ë§Œì¡±ë„ê°€ ë†’ìŠµë‹ˆë‹¤.'
        """
        try:
            response = await llm.ainvoke(prompt)
            return response.content.strip()
        except Exception as e:
            return "ê°ì„± ë¶„ì„ ì´ìœ  ìš”ì•½ ì¤‘ ì˜¤ë¥˜ ë°œìƒ"

    async def _generate_score_explanation(self, item: dict, is_festival: bool) -> str:
        llm = get_llm_client(temperature=0.3)

        # Prepare data for the prompt
        data = {
            "title": item.get("title"),
            "sentiment_score": item.get("sentiment_score"),
            "sentiment_reason": item.get("sentiment_reason"),
            "quarterly_trend_score": item.get("quarterly_trend_score"),
            "yearly_trend_score": item.get("yearly_trend_score"),
            "trend_reason": item.get("trend_reason"),
        }
        today_str = datetime.today().strftime("%Yë…„ %mì›” %dì¼")

        if is_festival:
            data["time_score"] = item.get("time_score")
            # Add festival dates to the data payload
            start_date = item.get("eventstartdate")
            end_date = item.get("eventenddate")
            if start_date and end_date:
                try:
                    data["festival_period"] = (
                        f"{datetime.strptime(str(start_date), '%Y%m%d').strftime('%Yë…„ %mì›” %dì¼')}ë¶€í„° {datetime.strptime(str(end_date), '%Y%m%d').strftime('%Yë…„ %mì›” %dì¼')}ê¹Œì§€"
                    )
                except (ValueError, TypeError):
                    pass  # Ignore if dates are not in the expected format

            score_definitions = """
            - â¤ï¸ ë§Œì¡±ë„ ì ìˆ˜: ì‹¤ì œ ë°©ë¬¸ê°ë“¤ì˜ ê¸ì •ì ì¸ ë¦¬ë·°ê°€ ì–¼ë§ˆë‚˜ ë§ì€ì§€ë¥¼ ë‚˜íƒ€ë‚´ìš”. (100ì ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ë§Œì¡±ë„ê°€ ë†’ìŒ)
            - ğŸ“… ì‹œê¸°ì„± ì ìˆ˜: ì§€ê¸ˆì´ ì´ ì¶•ì œë¥¼ ë°©ë¬¸í•˜ê¸° ì–¼ë§ˆë‚˜ ì¢‹ì€ ì‹œê¸°ì¸ì§€ë¥¼ ì•Œë ¤ì¤˜ìš”. (100ì ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¶•ì œê°€ í˜„ì¬ ì§„í–‰ì¤‘ì´ê±°ë‚˜ ê³§ ì‹œì‘í•œë‹¤ëŠ” ì˜ë¯¸)
            - ğŸ”¥ ìµœê·¼ í™”ì œì„± (90ì¼): ì§€ë‚œ 3ê°œì›” ë™ì•ˆ ì‚¬ëŒë“¤ì´ ì–¼ë§ˆë‚˜ ë§ì´ ê²€ìƒ‰í–ˆëŠ”ì§€ë¥¼ ë³´ì—¬ì¤˜ìš”.
            - ğŸ—“ï¸ ì—°ê°„ ê¾¸ì¤€í•¨ (365ì¼): 1ë…„ ë‚´ë‚´ ì–¼ë§ˆë‚˜ ê¾¸ì¤€íˆ ì¸ê¸°ê°€ ìˆì—ˆëŠ”ì§€ë¥¼ ë‚˜íƒ€ë‚´ìš”.
            """
            # New instruction for the prompt
            timeliness_instruction = f"""
        - 'ì‹œê¸°ì„± ì ìˆ˜'ë¥¼ ì„¤ëª…í•  ë•ŒëŠ” ì˜¤ëŠ˜ ë‚ ì§œ({today_str})ì™€ ì¶•ì œ ê¸°ê°„({data.get('festival_period', 'ì•Œ ìˆ˜ ì—†ìŒ')})ì„ í•¨ê»˜ ì–¸ê¸‰í•˜ë©° ì™œ ë°©ë¬¸í•˜ê¸° ì¢‹ì€ ì‹œê¸°ì¸ì§€(ë˜ëŠ” ì•„ë‹Œì§€) êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
        """
        else:
            data["distance_score"] = item.get("distance_score")
            raw_distance_m = item.get("distance")
            if raw_distance_m is not None:
                data["distance_in_km"] = f"{(raw_distance_m / 1000):.2f}km"

            score_definitions = """
            - â¤ï¸ ë§Œì¡±ë„ ì ìˆ˜: ì‹¤ì œ ë°©ë¬¸ê°ë“¤ì˜ ê¸ì •ì ì¸ ë¦¬ë·°ê°€ ì–¼ë§ˆë‚˜ ë§ì€ì§€ë¥¼ ë‚˜íƒ€ë‚´ìš”. (100ì ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ë§Œì¡±ë„ê°€ ë†’ìŒ)
            - ğŸ“ ê±°ë¦¬ ì ìˆ˜: ì›ë˜ ì°¾ìœ¼ë ¤ë˜ ì¶•ì œ ì¥ì†Œì—ì„œ ì–¼ë§ˆë‚˜ ê°€ê¹Œìš´ì§€ë¥¼ ì•Œë ¤ì¤˜ìš”. (100ì ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ê°€ê¹Œì›€)
            - ğŸ”¥ ìµœê·¼ í™”ì œì„± (90ì¼): ì§€ë‚œ 3ê°œì›” ë™ì•ˆ ì‚¬ëŒë“¤ì´ ì–¼ë§ˆë‚˜ ë§ì´ ê²€ìƒ‰í–ˆëŠ”ì§€ë¥¼ ë³´ì—¬ì¤˜ìš”.
            - ğŸ—“ï¸ ì—°ê°„ ê¾¸ì¤€í•¨ (365ì¼): 1ë…„ ë‚´ë‚´ ì–¼ë§ˆë‚˜ ê¾¸ì¤€íˆ ì¸ê¸°ê°€ ìˆì—ˆëŠ”ì§€ë¥¼ ë‚˜íƒ€ë‚´ìš”.
            """
            timeliness_instruction = f"""
        - 'ê±°ë¦¬ ì ìˆ˜'ë¥¼ ì„¤ëª…í•  ë•ŒëŠ” ì‹¤ì œ ê±°ë¦¬({data.get('distance_in_km', 'ì•Œ ìˆ˜ ì—†ìŒ')})ë¥¼ í•¨ê»˜ ì–¸ê¸‰í•˜ë©° ì–¼ë§ˆë‚˜ ê°€ê¹Œìš´ì§€(ë˜ëŠ” ë¨¼ì§€) êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
        """  # No special instruction for distance

        prompt = f"""
        ë‹¹ì‹ ì€ ë°ì´í„°ë¥¼ ì‰½ê³  ì¹œì ˆí•˜ê²Œ ì„¤ëª…í•´ì£¼ëŠ” ë¶„ì„ê°€ì…ë‹ˆë‹¤. ì•„ë˜ëŠ” '{data["title"]}'ì˜ ë¶„ì„ ë°ì´í„°ì…ë‹ˆë‹¤.

        [ì ìˆ˜ ì˜ë¯¸]
        {score_definitions}

        [ë¶„ì„ ë°ì´í„°]
        {json.dumps(data, ensure_ascii=False, indent=2)}

        [ìš”ì²­]
        ìœ„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ê° í•­ëª©ì— ëŒ€í•´ ì‚¬ìš©ìê°€ ì´í•´í•˜ê¸° ì‰½ê²Œ êµ¬ì²´ì ì¸ ì„¤ëª…ì„ ìƒì„±í•´ì£¼ì„¸ìš”.
        ì•„ë˜ ê·œì¹™ì„ ë°˜ë“œì‹œ ì§€ì¼œì£¼ì„¸ìš”.

        1. ê° í•­ëª©ì„ ì„¤ëª…í•  ë•Œ, ì ìˆ˜ì™€ í•¨ê»˜ ê·¸ ì ìˆ˜ê°€ ì˜ë¯¸í•˜ëŠ” ë°”ë¥¼ `sentiment_reason`ê³¼ `trend_reason`ì„ í™œìš©í•˜ì—¬ í’€ì–´ì„œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
        2. 'ë§Œì¡±ë„ ì ìˆ˜'ë¥¼ ì„¤ëª…í•  ë•ŒëŠ” `sentiment_reason`ì— ìˆëŠ” êµ¬ì²´ì ì¸ ì¹­ì°¬ ì´ìœ ë¥¼ ë°˜ë“œì‹œ í¬í•¨í•´ì£¼ì„¸ìš”.
        {timeliness_instruction}
        3. ë”±ë”±í•œ ë³´ê³ ì„œ í˜•ì‹ì´ ì•„ë‹Œ, ì¹œêµ¬ì—ê²Œ ë§í•˜ë“¯ ì¹œì ˆí•˜ê³  ë¶€ë“œëŸ¬ìš´ ì–´íˆ¬ë¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš”.
        4. "[ë¶„ì„]" ì´ë¼ëŠ” ë‹¨ì–´ë‚˜ ë¨¸ë¦¬ê¸€ì„ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
        5. ê° í•­ëª©ì„ ì„¤ëª…í•˜ëŠ” ë‚´ìš©ì„ Markdown ë¦¬ìŠ¤íŠ¸(-) í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.

        [ì¢‹ì€ ì¶œë ¥ ì˜ˆì‹œ (ì¶•ì œ)]
        - â¤ï¸ **ë§Œì¡±ë„**: 83.33ì ! ë°©ë¬¸ê°ë“¤ì´ 'ê¹¨ë—í•œ ì‹œì„¤ê³¼ ë‹¤ì–‘í•œ ë¨¹ê±°ë¦¬' ë•Œë¬¸ì— ì•„ì£¼ ë§Œì¡±í–ˆì–´ìš”.
        - ğŸ“… **ì‹œê¸°ì„±**: 100ì ! ì¶•ì œê°€ 2024ë…„ 10ì›” 25ì¼ë¶€í„° 2024ë…„ 11ì›” 3ì¼ê¹Œì§€ì¸ë°, ì˜¤ëŠ˜ì´ 10ì›” 26ì¼ì´ë‹ˆê¹Œ ì§€ê¸ˆ ë°”ë¡œ ì¶•ì œë¥¼ ì¦ê¸¸ ìˆ˜ ìˆëŠ” ì™„ë²½í•œ ì‹œê¸°ì˜ˆìš”.
        - ğŸ”¥ **í™”ì œì„±**: ìµœê·¼ 3ê°œì›”ê°„ ê´€ì‹¬ë„ê°€ 16.25ì ìœ¼ë¡œ ë‹¤ì†Œ ë‚®ì§€ë§Œ, 'íŠ¹ì • ë‚ ì§œì—ë§Œ ê´€ì‹¬ì´ ì§‘ì¤‘ë˜ëŠ” íŒ¨í„´'ì„ ë³´ì—¬ìš”. ì¡°ìš©í•œ ë°©ë¬¸ì„ ì›í•œë‹¤ë©´ ì§€ê¸ˆì´ ê¸°íšŒì¼ ìˆ˜ ìˆì–´ìš”. 1ë…„ ë‚´ë‚´ ê¾¸ì¤€í•œ ê´€ì‹¬ë„ëŠ” 13.47ì ìœ¼ë¡œ, ì•„ëŠ” ì‚¬ëŒë§Œ ì•„ëŠ” ìˆ¨ì€ ëª…ì†Œì¼ ê°€ëŠ¥ì„±ì´ ë†’ì•„ìš”.
        
        [ì¢‹ì€ ì¶œë ¥ ì˜ˆì‹œ (ì¥ì†Œ)]
        - â¤ï¸ **ë§Œì¡±ë„**: 90ì ! 'ì§ì›ë“¤ì´ ì¹œì ˆí•˜ê³  ì£¼ì°¨ì¥ì´ ë„“ë‹¤'ëŠ” ì ì—ì„œ ë°©ë¬¸ê°ë“¤ì˜ ë§Œì¡±ë„ê°€ ë§¤ìš° ë†’ì•„ìš”.
        - ğŸ“ **ê±°ë¦¬**: 85ì ! ì›ë˜ ê°€ë ¤ë˜ ì¶•ì œ ì¥ì†Œì—ì„œ ì•½ 1.25km ë–¨ì–´ì ¸ ìˆì–´ í•¨ê»˜ ë‘˜ëŸ¬ë³´ê¸° ì¢‹ì•„ìš”.
        - ğŸ”¥ **í™”ì œì„±**: 'ì£¼ë§ì— ê²€ìƒ‰ëŸ‰ì´ ê¸‰ì¦í•˜ëŠ” ê²½í–¥'ì„ ë³´ì—¬ìš”. ì—¬ìœ ë¡­ê²Œ ì¦ê¸°ê³  ì‹¶ë‹¤ë©´ í‰ì¼ì— ë°©ë¬¸í•˜ëŠ” ê±¸ ì¶”ì²œí•´ìš”.
        """
        try:
            response = await llm.ainvoke(prompt)
            return response.content.strip()
        except Exception as e:
            return "ì ìˆ˜ ì„¤ëª… ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

    async def _generate_comparative_summary(
        self, ranked_list: list, is_festival: bool
    ) -> str:
        llm = get_llm_client(temperature=0.3)

        # Dynamically create the data structure for the prompt based on context
        data_for_prompt = []
        for item in ranked_list:
            data = {
                "title": item.get("title"),
                "ranking_score": item.get("ranking_score"),
                "sentiment_score": item.get("sentiment_score"),
                "sentiment_reason": item.get("sentiment_reason"),
                "quarterly_trend_score": item.get("quarterly_trend_score"),
                "yearly_trend_score": item.get("yearly_trend_score"),
                "trend_reason": item.get("trend_reason"),
            }
            if is_festival:
                data["time_score"] = item.get("time_score")
            else:
                data["distance_score"] = item.get("distance_score")
            data_for_prompt.append(data)

        context_specific_meaning = (
            """
        - ì‹œê¸°ì„± ì ìˆ˜: í˜„ì¬ ì‹œì ì—ì„œ ì–¼ë§ˆë‚˜ ë°©ë¬¸í•˜ê¸° ì¢‹ì€ ì‹œê¸°ì¸ì§€ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. (100ì ì— ê°€ê¹Œìš¸ìˆ˜ë¡ í˜„ì¬ ì§„í–‰ì¤‘ì´ê±°ë‚˜ ê³§ ì‹œì‘í•¨ì„ ì˜ë¯¸)
        """
            if is_festival
            else """
        - ê±°ë¦¬ ì ìˆ˜: ì„ íƒí•œ ì¶•ì œ ì¥ì†Œì—ì„œ ì–¼ë§ˆë‚˜ ê°€ê¹Œìš´ì§€ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. (100ì ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ê°€ê¹Œì›€ì„ ì˜ë¯¸)
        """
        )

        prompt = f"""
        ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  í†µì°°ë ¥ ìˆëŠ” ì—¬í–‰ ì¶”ì²œ ë°ì´í„° ë¶„ì„ê°€ì…ë‹ˆë‹¤. ì•„ë˜ëŠ” ì—¬ëŸ¬ ì ìˆ˜ë¥¼ ì¢…í•©í•˜ì—¬ ìˆœìœ„ë¥¼ ë§¤ê¸´ ê´€ê´‘ì§€ ë˜ëŠ” ì¶•ì œ ëª©ë¡ì…ë‹ˆë‹¤.

        [ê° ì ìˆ˜ì˜ ì˜ë¯¸]
        - ë§Œì¡±ë„ ì ìˆ˜: ì‹¤ì œ ë°©ë¬¸ê°ë“¤ì´ ë¦¬ë·°ì—ì„œ ë‚¨ê¸´ ë§Œì¡±ë„ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. (100ì ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ê¸ì •ì  í‰ê°€ê°€ ë§ìŒ)
        - ìµœê·¼ í™”ì œì„± (90ì¼): ìµœê·¼ 3ê°œì›”ê°„ ëŒ€ì¤‘ì˜ ê´€ì‹¬ì´ ì–¼ë§ˆë‚˜ ëœ¨ê±°ìš´ì§€ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.
        - ì—°ê°„ ê¾¸ì¤€í•¨ (365ì¼): ì§€ë‚œ 1ë…„ê°„ ì–¼ë§ˆë‚˜ ê¾¸ì¤€íˆ ê´€ì‹¬ì„ ë°›ì•˜ëŠ”ì§€ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.
        {context_specific_meaning}

        [ë¶„ì„ ë°ì´í„°]
        {json.dumps(data_for_prompt, ensure_ascii=False, indent=2)}

        [ìš”ì²­]
        ìœ„ ë°ì´í„°ì™€ ê° ì ìˆ˜ì˜ ì˜ë¯¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ, 1ìœ„ê°€ ì™œ ìµœê³ ì˜ ì„ íƒì¸ì§€ ì‚¬ìš©ì ì¹œí™”ì ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”. ì•„ë˜ ê·œì¹™ì„ ë°˜ë“œì‹œ ì§€ì¼œì£¼ì„¸ìš”.
        
        1. "1ìœ„ëŠ” OOOì…ë‹ˆë‹¤" ë¼ê³  ì‹œì‘í•˜ì§€ ë§ê³ , "ì´ë²ˆ ì¶”ì²œì—ì„œëŠ” OOOì´(ê°€) ê°€ì¥ ë†’ì€ ì ìˆ˜ë¥¼ ë°›ì•˜ë„¤ìš”!" ì™€ ê°™ì´ ì¹œêµ¬ì²˜ëŸ¼ ìì—°ìŠ¤ëŸ½ê²Œ ì‹œì‘í•´ì£¼ì„¸ìš”.
        2. ê° ì ìˆ˜ê°€ ì™œ ë†’ì€ì§€(ë˜ëŠ” ë‚®ì€ì§€) `sentiment_reason`ê³¼ `trend_reason`ì„ ì¸ìš©í•˜ì—¬ êµ¬ì²´ì ì¸ ì´ìœ ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”.
        3. ë‹¤ë¥¸ ìˆœìœ„ì™€ ë¹„êµí•˜ì—¬ 1ìœ„ê°€ ê°€ì§„ ê°•ì ì„ ë¶€ê°í•´ì£¼ì„¸ìš”.
        4. 2~3 ë¬¸ì¥ì˜ ê°„ê²°í•˜ê³  ì„¤ë“ë ¥ ìˆëŠ” ìš”ì•½ë¬¸ìœ¼ë¡œ ë§ˆë¬´ë¦¬í•´ì£¼ì„¸ìš”.

        [ì¢‹ì€ ìš”ì•½ ì˜ˆì‹œ]
        "ì´ë²ˆ ì¶”ì²œì—ì„œëŠ” OOOì´(ê°€) ê°€ì¥ ë†’ì€ ì ìˆ˜ë¥¼ ë°›ì•˜ë„¤ìš”! ë¬´ì—‡ë³´ë‹¤ ì‹¤ì œ ë°©ë¬¸ê°ë“¤ì´ 'ì•„ì´ë“¤ê³¼ ì¦ê¸¸ ê±°ë¦¬ê°€ ë§ë‹¤'ëŠ” ì ì—ì„œ ë†’ì€ ë§Œì¡±ë„ë¥¼ ë³´ì˜€ê³ , ìµœê·¼ 3ê°œì›”ê°„ ê²€ìƒ‰ëŸ‰ì´ ê¾¸ì¤€íˆ ì¦ê°€í•˜ë©° ëœ¨ê±°ìš´ ê´€ì‹¬ì„ ë°›ê³  ìˆë‹¤ëŠ” ì ì´ í° ê°•ì ì…ë‹ˆë‹¤. 2ìœ„ì¸ XXXì— ë¹„í•´ ì—°ê°„ ê¾¸ì¤€í•¨ì€ ì¡°ê¸ˆ ë‚®ì§€ë§Œ, ì§€ê¸ˆ ë‹¹ì¥ ë°©ë¬¸í•˜ê¸° ì¢‹ì€ ì‹œê¸°ë¼ëŠ” ì ê³¼ ë†’ì€ ë§Œì¡±ë„ë¥¼ ê³ ë ¤í–ˆì„ ë•Œ ìµœê³ ì˜ ì„ íƒì´ë¼ê³  í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        """
        try:
            response = await llm.ainvoke(prompt)
            return response.content.strip()
        except Exception as e:
            return "ìµœì¢… ë¶„ì„ ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

    async def generate_ranking_report(
        self, ranked_list: list, top_n: int, is_festival: bool
    ) -> str:
        top_n = int(top_n)
        if not ranked_list or not any(
            item.get("ranking_score", 0) > 0 for item in ranked_list[:top_n]
        ):
            return "ìŠ¤ì½”ì–´ë§ëœ í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤."

        comparative_summary = await self._generate_comparative_summary(
            ranked_list[:top_n], is_festival
        )
        report_parts = [f"## ğŸ† ìµœì¢… ìˆœìœ„ ë¶„ì„\n{comparative_summary}", "---"]
        top_items = ranked_list[:top_n]
        medals = ["ğŸ¥‡", "ğŸ¥ˆ", "ğŸ¥‰", "4ï¸âƒ£", "5ï¸âƒ£"]

        for i, item in enumerate(top_items):
            rank_indicator = medals[i] if i < len(medals) else f"{i+1}ìœ„"
            title = item.get("title", "N/A")
            total_score = item.get("ranking_score", "N/A")
            image_url = item.get("firstimage", NO_IMAGE_URL) or NO_IMAGE_URL

            # Generate the user-friendly explanation for the scores
            explanation = await self._generate_score_explanation(item, is_festival)

            report_parts.append(
                f"### {rank_indicator} {i+1}ìœ„: {title} (ì¢…í•© ì ìˆ˜: {total_score})"
            )
            report_parts.append(f"![{title}]({image_url})\n")
            report_parts.append(explanation)
            report_parts.append("---")

        return "\n\n".join(report_parts)

    async def rank_places(
        self,
        places_list: list,
        num_reviews: int,
        top_n: int,
        progress=None,
        is_course: bool = False,
    ):
        if not places_list:
            return [], "ëª©ë¡ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.", [], ""

        # Find max distance for normalization
        distances = [
            p.get("distance", 0) for p in places_list if p.get("distance") is not None
        ]
        max_dist = max(distances) if distances else 0

        async def process_place(place):
            # 1. Calculate Distance Score
            distance = place.get("distance")
            distance_score = 0
            if distance is not None:
                if max_dist > 0:
                    distance_score = 1 - (distance / max_dist)
                else:
                    distance_score = 1.0
            place["distance_score"] = round(distance_score * 100, 2)

            # 2. Calculate Trend and Sentiment Scores
            if is_course:
                course_title = place.get("title", "")
                sub_points = place.get("sub_points", [])
                if not sub_points:
                    place["ranking_score"] = 0
                    return place

                q_trend_scores, y_trend_scores, sentiment_scores, all_judgments = (
                    [],
                    [],
                    [],
                    [],
                )
                for sub in sub_points:
                    sub_title = sub.get("subname", "")
                    if not sub_title:
                        continue
                    q_trend_scores.append(self._get_trend_score(sub_title, days=90))
                    y_trend_scores.append(self._get_trend_score(sub_title, days=365))
                    s_score, judgments = await self._get_sentiment_score(
                        sub_title, num_reviews
                    )
                    sentiment_scores.append(s_score)
                    all_judgments.extend(judgments)

                place["quarterly_trend_score"] = (
                    round(sum(q_trend_scores) / len(q_trend_scores), 2)
                    if q_trend_scores
                    else 0
                )
                place["yearly_trend_score"] = (
                    round(sum(y_trend_scores) / len(y_trend_scores), 2)
                    if y_trend_scores
                    else 0
                )
                place["sentiment_score"] = (
                    round(sum(sentiment_scores) / len(sentiment_scores), 2)
                    if sentiment_scores
                    else 50
                )

                trend_reason, sentiment_reason = await asyncio.gather(
                    self._summarize_trend_reasons(course_title),
                    self._summarize_sentiment_reasons(all_judgments, course_title),
                )
            else:
                title = place.get("title", "")
                quarterly_trend_score = self._get_trend_score(title, days=90)
                yearly_trend_score = self._get_trend_score(title, days=365)
                sentiment_score, judgments = await self._get_sentiment_score(
                    title, num_reviews
                )

                place["quarterly_trend_score"] = round(quarterly_trend_score, 2)
                place["yearly_trend_score"] = round(yearly_trend_score, 2)
                place["sentiment_score"] = round(sentiment_score, 2)

                trend_reason, sentiment_reason = await asyncio.gather(
                    self._summarize_trend_reasons(title),
                    self._summarize_sentiment_reasons(judgments, title),
                )

            # 3. Calculate Final Weighted Score
            w_dist = 0.3
            w_sentiment = 0.4
            w_trend_quarterly = 0.2
            w_trend_yearly = 0.1

            final_score = (
                (place["distance_score"] * w_dist)
                + (place["sentiment_score"] * w_sentiment)
                + (place["quarterly_trend_score"] * w_trend_quarterly)
                + (place["yearly_trend_score"] * w_trend_yearly)
            )
            place["ranking_score"] = round(final_score, 2)

            place["trend_reason"] = trend_reason
            place["sentiment_reason"] = sentiment_reason
            return place

        tasks = [process_place(p) for p in places_list]
        ranked_places = []

        # Use progress if available (Gradio), otherwise just gather tasks
        if progress:
            for task in progress.tqdm(
                asyncio.as_completed(tasks), total=len(tasks), desc="ì¥ì†Œ ì ìˆ˜ ê³„ì‚° ì¤‘"
            ):
                ranked_places.append(await task)
        else:
            ranked_places = await asyncio.gather(*tasks)

        ranked_places.sort(key=lambda x: x.get("ranking_score", 0), reverse=True)
        gallery_output = [
            (
                item.get("firstimage", NO_IMAGE_URL) or NO_IMAGE_URL,
                f"ì ìˆ˜: {item.get('ranking_score')} - {item['title']}",
            )
            for item in ranked_places
        ]
        report_md = await self.generate_ranking_report(
            ranked_places, top_n, is_festival=False
        )

        return ranked_places, "ìˆœìœ„ ê³„ì‚° ì™„ë£Œ!", gallery_output, report_md

    def _get_time_score(self, start_date_str: str, end_date_str: str) -> float:
        if not start_date_str or not end_date_str:
            return 0.0

        today = datetime.today().date()

        try:
            original_start_date = datetime.strptime(
                str(start_date_str).split(".")[0], "%Y%m%d"
            ).date()
            original_end_date = datetime.strptime(
                str(end_date_str).split(".")[0], "%Y%m%d"
            ).date()
        except (ValueError, TypeError):
            return 0.0

        is_projected = False  # Flag to track if the date is an assumption

        # Case 1: Festival is currently ongoing.
        if original_start_date <= today <= original_end_date:
            return 1.0

        # Case 2: Festival has already ended.
        if original_end_date < today:
            is_projected = True  # Mark this as a projection
            prospective_start_date = original_start_date
            while prospective_start_date <= today:
                prospective_start_date = (
                    pd.to_datetime(prospective_start_date) + pd.DateOffset(years=1)
                ).date()

            days_until_start = (prospective_start_date - today).days

        # Case 3: Festival is in the future.
        else:  # original_start_date > today
            days_until_start = (original_start_date - today).days

        # Apply tiered scoring
        score = 0.0
        if 0 <= days_until_start <= 7:
            score = 0.9
        elif 8 <= days_until_start <= 30:
            score = 0.6
        elif 31 <= days_until_start <= 90:
            score = 0.3
        else:  # More than 90 days away
            score = 0.1

        # Apply penalty if the date was projected
        if is_projected:
            penalty_multiplier = 0.8  # 20% penalty
            score *= penalty_multiplier

        return score

    async def rank_festivals(
        self, festivals_list: list, num_reviews: int, top_n: int, progress=None
    ):
        if not festivals_list:
            return [], ""

        async def process_festival(festival):
            title = festival.get("title", "")
            start_date = festival.get("eventstartdate")
            end_date = festival.get("eventenddate")

            # 1. Calculate Time Score
            time_score = self._get_time_score(start_date, end_date)
            festival["time_score"] = round(time_score * 100, 2)

            # 2. Calculate Trend and Sentiment Scores
            quarterly_trend_score = self._get_trend_score(title, days=90)
            yearly_trend_score = self._get_trend_score(title, days=365)
            sentiment_score, judgments = await self._get_sentiment_score(
                title, num_reviews
            )

            festival["quarterly_trend_score"] = round(quarterly_trend_score, 2)
            festival["yearly_trend_score"] = round(yearly_trend_score, 2)
            festival["sentiment_score"] = round(sentiment_score, 2)

            # Get reasons for scores
            trend_reason, sentiment_reason = await asyncio.gather(
                self._summarize_trend_reasons(title),
                self._summarize_sentiment_reasons(judgments, title),
            )
            festival["trend_reason"] = trend_reason
            festival["sentiment_reason"] = sentiment_reason

            # 3. Calculate Final Weighted Score
            w_time = 0.6
            w_sentiment = 0.2
            w_trend_quarterly = 0.1
            w_trend_yearly = 0.1

            final_score = (
                (festival["time_score"] * w_time)
                + (festival["sentiment_score"] * w_sentiment)
                + (festival["quarterly_trend_score"] * w_trend_quarterly)
                + (festival["yearly_trend_score"] * w_trend_yearly)
            )
            festival["ranking_score"] = round(final_score, 2)

            return festival

        tasks = [process_festival(f) for f in festivals_list]
        ranked_festivals = []

        # Use progress if available (Gradio), otherwise just gather tasks
        if progress:
            for task in progress.tqdm(
                asyncio.as_completed(tasks), total=len(tasks), desc="ì¶•ì œ ìˆœìœ„ ê³„ì‚° ì¤‘"
            ):
                ranked_festivals.append(await task)
        else:
            ranked_festivals = await asyncio.gather(*tasks)

        ranked_festivals.sort(key=lambda x: x.get("ranking_score", 0), reverse=True)

        report_md = await self.generate_ranking_report(
            ranked_festivals, top_n, is_festival=True
        )

        return ranked_festivals, report_md
